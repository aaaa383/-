{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "#from mlxtend.regressor import StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2266 entries, 13994 to 16436\n",
      "Data columns (total 44 columns):\n",
      "away           2266 non-null object\n",
      "gameday        2266 non-null object\n",
      "home           2266 non-null object\n",
      "id             2266 non-null int64\n",
      "match          2266 non-null object\n",
      "stadium        2266 non-null object\n",
      "stage          2266 non-null object\n",
      "time           2266 non-null object\n",
      "tv             2266 non-null object\n",
      "y              1953 non-null float64\n",
      "year           2266 non-null int64\n",
      "home_score     2266 non-null int64\n",
      "away_score     2266 non-null int64\n",
      "weather        2266 non-null object\n",
      "temperature    2266 non-null float64\n",
      "humidity       2266 non-null object\n",
      "referee        2266 non-null object\n",
      "home_team      2266 non-null object\n",
      "home_01        2266 non-null object\n",
      "home_02        2266 non-null object\n",
      "home_03        2266 non-null object\n",
      "home_04        2266 non-null object\n",
      "home_05        2266 non-null object\n",
      "home_06        2266 non-null object\n",
      "home_07        2266 non-null object\n",
      "home_08        2266 non-null object\n",
      "home_09        2266 non-null object\n",
      "home_10        2266 non-null object\n",
      "home_11        2266 non-null object\n",
      "away_team      2266 non-null object\n",
      "away_01        2266 non-null object\n",
      "away_02        2266 non-null object\n",
      "away_03        2266 non-null object\n",
      "away_04        2266 non-null object\n",
      "away_05        2266 non-null object\n",
      "away_06        2266 non-null object\n",
      "away_07        2266 non-null object\n",
      "away_08        2266 non-null object\n",
      "away_09        2266 non-null object\n",
      "away_10        2266 non-null object\n",
      "away_11        2266 non-null object\n",
      "name           2266 non-null object\n",
      "address        2266 non-null object\n",
      "capa           2266 non-null int64\n",
      "dtypes: float64(2), int64(5), object(37)\n",
      "memory usage: 796.6+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.concat([pd.read_csv('../input_data/jleague/train.csv'),\n",
    "                      pd.read_csv('../input_data/jleague/train_add.csv')])\n",
    "test_df = pd.read_csv('../input_data/jleague/test.csv')\n",
    "\n",
    "n_train, n_test = len(train_df), len(test_df)\n",
    "\n",
    "condition_df = pd.concat([pd.read_csv('../input_data/jleague/condition.csv'),\n",
    "                          pd.read_csv('../input_data/jleague/condition_add.csv')])\n",
    "stadium_df = pd.read_csv('../input_data/jleague/stadium.csv')\n",
    "\n",
    "# 学習データ，テストデータ，追加データを結合\n",
    "all_df = pd.concat([train_df, test_df])\n",
    "all_df = pd.merge(all_df, condition_df, on='id')\n",
    "all_df = pd.merge(all_df, stadium_df, how='left', left_on='stadium', right_on='name')\n",
    "all_df.index = all_df['id']\n",
    "\n",
    "all_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 開催節\n",
    "all_df['match_sec'] = all_df['match'].apply(lambda x: int(x[1:].split('節')[0]))\n",
    "all_df['match_day'] = all_df['match'].apply(lambda x: int(x[:-1].rsplit('第', 1)[-1]))\n",
    "\n",
    "# 開催日時\n",
    "all_df['gamemonth'] = all_df['gameday'].apply(lambda x: int(x.split('/', 1)[0]))\n",
    "all_df['weekday'] = all_df['gameday'].apply(lambda x: x[:-1].rsplit('(', 1)[-1])\n",
    "all_df['holiday'] = all_df['weekday'].apply(lambda x: 1 if x in list('土日') or '祝' in x or '休' in x else 0)\n",
    "all_df['time_hour'] = all_df['time'].apply(lambda x: int(x.split(':')[0]))\n",
    "\n",
    "# TV\n",
    "all_df['terrestrial'] = all_df['tv'].apply(lambda x:1 if any(['ＢＳ－' not in tv and\n",
    "                                                              'スカパー' not in tv and\n",
    "                                                              'ＢＳ１' not in tv and\n",
    "                                                              'ｅ２' not in tv for tv in x.split('／')]) else 0)\n",
    "all_df['recorded'] = all_df['tv'].apply(lambda x: 1 if '（録）' in x else 0)\n",
    "\n",
    "# 天気\n",
    "all_df['rain'] = all_df['weather'].apply(lambda x: 1 if '雨' == x else 0)\n",
    "all_df['precipitation'] = all_df['weather'].apply(lambda x: 1 if '雨' in x else 0)\n",
    "\n",
    "# 屋内\n",
    "all_df['indoor'] = all_df['weather'].apply(lambda x: 1 if x == '屋内' else 0)\n",
    "\n",
    "# 県\n",
    "all_df['prefecture'] = all_df['address'].apply(lambda x: re.split(r'都|道|府|県', x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- カテゴリデータをダミー変数に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_cols = ['match_sec', 'gamemonth', 'holiday', 'time_hour', 'terrestrial', 'recorded',\n",
    "            'rain', 'precipitation', 'indoor', 'home_score', 'away_score', 'capa',]\n",
    "cat_cols = ['weekday', 'stage', 'home', 'away', 'stadium', 'weather', 'prefecture']\n",
    "\n",
    "df = all_df[val_cols].join(pd.get_dummies(all_df[cat_cols]))\n",
    "\n",
    "X = df[:n_train].values\n",
    "y = train_df['y'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの選択と学習\n",
    "- いくつかモデルを試してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score  : 3521.99028 +/- 503.29339\n",
      "test score: 3108.09986\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "scores = np.sqrt(-scores)\n",
    "print('cv score  : {:.5f} +/- {:.5f}'.format(scores.mean(), scores.std()))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print('test score: {:.5f}'.format(np.sqrt(mean_squared_error(y_val, model.predict(X_val)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score  : 3528.57977 +/- 508.95193\n",
      "test score: 3108.85412\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "scores = np.sqrt(-scores)\n",
    "print('cv score  : {:.5f} +/- {:.5f}'.format(scores.mean(), scores.std()))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print('test score: {:.5f}'.format(np.sqrt(mean_squared_error(y_val, model.predict(X_val)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score  : 3444.56050 +/- 362.92945\n",
      "test score: 3105.91638\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(RobustScaler(), Lasso(alpha=10.0, max_iter=10000))\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "scores = np.sqrt(-scores)\n",
    "print('cv score  : {:.5f} +/- {:.5f}'.format(scores.mean(), scores.std()))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print('test score: {:.5f}'.format(np.sqrt(mean_squared_error(y_val, model.predict(X_val)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ステージ(J1, J2)でモデルを分割\n",
    "- J1とJ2で観客動員数の分布が異なっていたので，モデルを分けて学習する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_J1 = df[:n_train][df[:n_train]['stage_Ｊ１'] == 1].values\n",
    "y_J1 = train_df[train_df['stage'] == 'Ｊ１']['y'].values\n",
    "n_J1 = len(X_J1)\n",
    "\n",
    "X_J2 = df[:n_train][df[:n_train]['stage_Ｊ２'] == 1].values\n",
    "y_J2 = train_df[train_df['stage'] == 'Ｊ２']['y'].values\n",
    "n_J2 = len(X_J2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J1 cv score  : 4716.26604 +/- 872.98448\n",
      "J2 cv score  : 2015.97230 +/- 219.10440\n",
      "total cv score  : 3346.51234 +/- 559.94246\n"
     ]
    }
   ],
   "source": [
    "model_J1 = GradientBoostingRegressor()\n",
    "scores_J1 = -cross_val_score(model_J1, X_J1, y_J1, cv=5, scoring='neg_mean_squared_error')\n",
    "scores = np.sqrt(scores_J1)\n",
    "print('J1 cv score  : {:.5f} +/- {:.5f}'.format(scores.mean(), scores.std()))\n",
    "\n",
    "model_J2 = GradientBoostingRegressor()\n",
    "scores_J2 = -cross_val_score(model_J2, X_J2, y_J2, cv=5, scoring='neg_mean_squared_error')\n",
    "scores = np.sqrt(scores_J2)\n",
    "print('J2 cv score  : {:.5f} +/- {:.5f}'.format(scores.mean(), scores.std()))\n",
    "\n",
    "total = np.sqrt((scores_J1 * n_J1 + scores_J2 * n_J2) / (n_J1 + n_J2))\n",
    "print('total cv score  : {:.5f} +/- {:.5f}'.format(total.mean(), total.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J1 cv score  : 4676.28616 +/- 876.80993\n",
      "J2 cv score  : 2000.66681 +/- 209.32794\n",
      "total cv score  : 3319.93063 +/- 553.46979\n"
     ]
    }
   ],
   "source": [
    "model_J1 = make_pipeline(RobustScaler(), Lasso(alpha=20.0, max_iter=10000))\n",
    "scores_J1 = -cross_val_score(model_J1, X_J1, y_J1, cv=5, scoring='neg_mean_squared_error')\n",
    "scores = np.sqrt(scores_J1)\n",
    "print('J1 cv score  : {:.5f} +/- {:.5f}'.format(scores.mean(), scores.std()))\n",
    "\n",
    "model_J2 = make_pipeline(RobustScaler(), Lasso(alpha=3.5, max_iter=10000))\n",
    "scores_J2 = -cross_val_score(model_J2, X_J2, y_J2, cv=5, scoring='neg_mean_squared_error')\n",
    "scores = np.sqrt(scores_J2)\n",
    "print('J2 cv score  : {:.5f} +/- {:.5f}'.format(scores.mean(), scores.std()))\n",
    "\n",
    "total = np.sqrt((scores_J1 * n_J1 + scores_J2 * n_J2) / (n_J1 + n_J2))\n",
    "print('total cv score  : {:.5f} +/- {:.5f}'.format(total.mean(), total.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging\n",
    "- 各モデルの予測を平均する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class AverageRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, regressors):\n",
    "        self.regressors = regressors\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for reg in self.regressors:\n",
    "            reg.fit(X, y)\n",
    "    \n",
    "    def predict(self, X, weights=None):\n",
    "        if weights is None:\n",
    "            weights = np.ones(len(self.regressors))\n",
    "        assert len(weights) == len(self.regressors)\n",
    "        y = [w * reg.predict(X) for reg, w in zip(self.regressors, weights)]\n",
    "        return np.mean(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J1 cv score  : 4563.62484 +/- 888.26613\n",
      "J2 cv score  : 1942.95581 +/- 219.62569\n",
      "total cv score  : 3236.09858 +/- 565.98802\n"
     ]
    }
   ],
   "source": [
    "model_J1 = AverageRegressor([GradientBoostingRegressor(), make_pipeline(RobustScaler(), Lasso(alpha=20.0, max_iter=10000))])\n",
    "scores_J1 = -cross_val_score(model_J1, X_J1, y_J1, cv=5, scoring='neg_mean_squared_error')\n",
    "scores = np.sqrt(scores_J1)\n",
    "print('J1 cv score  : {:.5f} +/- {:.5f}'.format(scores.mean(), scores.std()))\n",
    "\n",
    "model_J2 = AverageRegressor([GradientBoostingRegressor(), make_pipeline(RobustScaler(), Lasso(alpha=3.5, max_iter=10000))])\n",
    "scores_J2 = -cross_val_score(model_J2, X_J2, y_J2, cv=5, scoring='neg_mean_squared_error')\n",
    "scores = np.sqrt(scores_J2)\n",
    "print('J2 cv score  : {:.5f} +/- {:.5f}'.format(scores.mean(), scores.std()))\n",
    "\n",
    "total = np.sqrt((scores_J1 * n_J1 + scores_J2 * n_J2) / (n_J1 + n_J2))\n",
    "print('total cv score  : {:.5f} +/- {:.5f}'.format(total.mean(), total.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_J1 = AverageRegressor([GradientBoostingRegressor(), make_pipeline(RobustScaler(), Lasso(alpha=20.0, max_iter=10000))])\n",
    "model_J2 = AverageRegressor([GradientBoostingRegressor(), make_pipeline(RobustScaler(), Lasso(alpha=3.5, max_iter=10000))])\n",
    "\n",
    "model_J1.fit(X_J1, y_J1)\n",
    "model_J2.fit(X_J2, y_J2)\n",
    "\n",
    "df_J1_test = df[n_train:][df[n_train:]['stage_Ｊ１'] == 1]\n",
    "df_J2_test = df[n_train:][df[n_train:]['stage_Ｊ２'] == 1]\n",
    "\n",
    "df_J1_test['y'] = model_J1.predict(df_J1_test.values)\n",
    "df_J2_test['y'] = model_J2.predict(df_J2_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([df_J1_test[['y']], df_J2_test[['y']]]).sort_index()\n",
    "df_test.to_csv('../submit/split_stage.csv', header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
